{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/udeepa/Documents/UCL/Term 2/bio/proteios\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import collections\n",
    "import pickle\n",
    "import copy\n",
    "import collections\n",
    "\n",
    "from Bio import SeqIO\n",
    "\n",
    "from proteios.preprocess import preprocess, split_data\n",
    "from proteios.featurise import Featuriser\n",
    "from proteios.cross_val import cross_validate\n",
    "from proteios.results import make_row, get_conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"input_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Cytosolic': 0, 'Secreted': 1, 'Mitochondrial': 2, 'Nuclear': 3}\n",
      "{'Cytosolic': 3004, 'Secreted': 1605, 'Mitochondrial': 1299, 'Nuclear': 3314, 'total': 9222}\n",
      "Number of test data points:   20\n"
     ]
    }
   ],
   "source": [
    "classes = [\"Cytosolic\", \"Secreted\", \"Mitochondrial\", \"Nuclear\"]\n",
    "\n",
    "# Get dictionaries for labels\n",
    "label2index = {key:i for i, key in enumerate(classes)}\n",
    "index2label = dict(zip(label2index.values(), label2index.keys())) \n",
    "\n",
    "# Get data\n",
    "datasets = dict()\n",
    "for label in classes:\n",
    "    datasets[label] = list(SeqIO.parse(input_path+label+\".fasta\", \"fasta\"))\n",
    "# Get test data\n",
    "blind_test_x = list(SeqIO.parse(input_path+\"blind_test.fasta\", \"fasta\"))\n",
    "\n",
    "# Get number of examples in each category\n",
    "counts = {key:len(val) for i, (key,val) in enumerate(datasets.items())}\n",
    "counts[\"total\"] = sum([len(sublist) for keys, sublist in datasets.items()])\n",
    "print(label2index)\n",
    "print(counts)\n",
    "print(\"Number of test data points:  \", len(blind_test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Cytosolic\n",
      "Data removed:  80\n",
      "Processing Secreted\n",
      "Data removed:  19\n",
      "Processing Mitochondrial\n",
      "Data removed:  2\n",
      "Processing Nuclear\n",
      "Data removed:  66\n",
      "Total Before:  9222\n",
      "Total After:   9055\n",
      "\n",
      "Processing tmp\n",
      "Data removed:  0\n",
      "Total Before:  20\n",
      "Total After:   20\n",
      "\n",
      "Distribution Full:   {3: 3248, 0: 2924, 2: 1297, 1: 1586}\n",
      "\n",
      "Training data size:  8148\n",
      "Test data size:      907\n",
      "Distribution train:  {1: 1427, 2: 1167, 3: 2923, 0: 2631}\n",
      "Distribution test:   {3: 325, 0: 293, 1: 159, 2: 130}\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the data\n",
    "full_x, full_y = preprocess(datasets, \n",
    "                            label2index=label2index,\n",
    "                            trim_outliers=True,\n",
    "                            max_length=2000)\n",
    "print()\n",
    "blind_test_xs = preprocess(blind_test_x, \n",
    "                           trim_outliers=True,\n",
    "                           max_length=2000)\n",
    "# Split the data\n",
    "train_x, train_y, test_x, test_y = split_data(full_x, \n",
    "                                              full_y,\n",
    "                                              train_size=0.9)\n",
    "print()\n",
    "print(\"Distribution Full:  \", dict(collections.Counter(full_y)))\n",
    "print()\n",
    "print(\"Training data size: \", len(train_y))\n",
    "print(\"Test data size:     \", len(test_y))\n",
    "print(\"Distribution train: \", dict(collections.Counter(train_y)))\n",
    "print(\"Distribution test:  \", dict(collections.Counter(test_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dictionaries\n",
    "dicts = dict()\n",
    "dicts['kd'] = pickle.load(open(\"input_data/scales/kd.pickle\",\"rb\"))\n",
    "dicts['flex'] = pickle.load(open(\"input_data/scales/flex.pickle\",\"rb\"))\n",
    "dicts['hw'] = pickle.load(open(\"input_data/scales/hw.pickle\",\"rb\"))\n",
    "dicts['em'] = pickle.load(open(\"input_data/scales/em.pickle\",\"rb\"))\n",
    "dicts['ja'] = pickle.load(open(\"input_data/scales/ja.pickle\",\"rb\"))\n",
    "dicts['diwv'] = pickle.load(open(\"input_data/scales/diwv.pickle\",\"rb\"))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuriser = Featuriser(full_x, dicts)\n",
    "full_x  = featuriser.transform(full_x)\n",
    "blind_test_x  = featuriser.transform(blind_test_xs)\n",
    "train_x = featuriser.transform(train_x)\n",
    "test_x  = featuriser.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>molecular_weight</th>\n",
       "      <th>isoelectric_point</th>\n",
       "      <th>aromaticity</th>\n",
       "      <th>instability_index</th>\n",
       "      <th>gravy</th>\n",
       "      <th>reduced</th>\n",
       "      <th>oxidised</th>\n",
       "      <th>helix</th>\n",
       "      <th>turn</th>\n",
       "      <th>...</th>\n",
       "      <th>last_50_M</th>\n",
       "      <th>last_50_N</th>\n",
       "      <th>last_50_P</th>\n",
       "      <th>last_50_Q</th>\n",
       "      <th>last_50_R</th>\n",
       "      <th>last_50_S</th>\n",
       "      <th>last_50_T</th>\n",
       "      <th>last_50_V</th>\n",
       "      <th>last_50_W</th>\n",
       "      <th>last_50_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.806657</td>\n",
       "      <td>-0.800262</td>\n",
       "      <td>-0.755535</td>\n",
       "      <td>0.242616</td>\n",
       "      <td>-0.007247</td>\n",
       "      <td>0.305557</td>\n",
       "      <td>-0.509198</td>\n",
       "      <td>-0.508647</td>\n",
       "      <td>0.225385</td>\n",
       "      <td>0.012791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854124</td>\n",
       "      <td>-0.162842</td>\n",
       "      <td>0.138739</td>\n",
       "      <td>-0.110699</td>\n",
       "      <td>-0.806124</td>\n",
       "      <td>1.403898</td>\n",
       "      <td>-0.862108</td>\n",
       "      <td>-0.952807</td>\n",
       "      <td>0.422678</td>\n",
       "      <td>1.064776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.098142</td>\n",
       "      <td>-1.107773</td>\n",
       "      <td>1.170813</td>\n",
       "      <td>-1.528243</td>\n",
       "      <td>1.152644</td>\n",
       "      <td>0.437546</td>\n",
       "      <td>-0.901343</td>\n",
       "      <td>-0.906719</td>\n",
       "      <td>-0.683724</td>\n",
       "      <td>-0.370318</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016389</td>\n",
       "      <td>-0.162842</td>\n",
       "      <td>-0.289219</td>\n",
       "      <td>1.401648</td>\n",
       "      <td>0.907851</td>\n",
       "      <td>-0.787258</td>\n",
       "      <td>0.793750</td>\n",
       "      <td>-0.426707</td>\n",
       "      <td>1.502267</td>\n",
       "      <td>-0.978975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.204178</td>\n",
       "      <td>0.224480</td>\n",
       "      <td>-0.802786</td>\n",
       "      <td>-0.099287</td>\n",
       "      <td>0.501211</td>\n",
       "      <td>0.927303</td>\n",
       "      <td>-0.435840</td>\n",
       "      <td>-0.429789</td>\n",
       "      <td>1.107682</td>\n",
       "      <td>-1.160093</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.886903</td>\n",
       "      <td>-1.227841</td>\n",
       "      <td>2.278529</td>\n",
       "      <td>0.897533</td>\n",
       "      <td>-0.806124</td>\n",
       "      <td>-0.056872</td>\n",
       "      <td>-0.862108</td>\n",
       "      <td>-0.426707</td>\n",
       "      <td>-0.656912</td>\n",
       "      <td>-0.297724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.046402</td>\n",
       "      <td>0.014496</td>\n",
       "      <td>1.297457</td>\n",
       "      <td>-1.188117</td>\n",
       "      <td>0.861330</td>\n",
       "      <td>0.038925</td>\n",
       "      <td>-0.447164</td>\n",
       "      <td>-0.428812</td>\n",
       "      <td>-1.140829</td>\n",
       "      <td>0.386568</td>\n",
       "      <td>...</td>\n",
       "      <td>2.595151</td>\n",
       "      <td>0.369657</td>\n",
       "      <td>3.990361</td>\n",
       "      <td>-0.614815</td>\n",
       "      <td>-0.806124</td>\n",
       "      <td>-0.422065</td>\n",
       "      <td>1.345703</td>\n",
       "      <td>0.099393</td>\n",
       "      <td>0.422678</td>\n",
       "      <td>-0.978975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.899461</td>\n",
       "      <td>0.985599</td>\n",
       "      <td>-0.890165</td>\n",
       "      <td>1.067473</td>\n",
       "      <td>-0.433540</td>\n",
       "      <td>0.389393</td>\n",
       "      <td>0.506489</td>\n",
       "      <td>0.504784</td>\n",
       "      <td>1.612466</td>\n",
       "      <td>-0.363544</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854124</td>\n",
       "      <td>-0.695342</td>\n",
       "      <td>-1.145135</td>\n",
       "      <td>-0.110699</td>\n",
       "      <td>0.907851</td>\n",
       "      <td>-0.787258</td>\n",
       "      <td>-0.862108</td>\n",
       "      <td>1.151592</td>\n",
       "      <td>0.422678</td>\n",
       "      <td>0.383526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     length  molecular_weight  isoelectric_point  aromaticity  \\\n",
       "0 -0.806657         -0.800262          -0.755535     0.242616   \n",
       "1 -1.098142         -1.107773           1.170813    -1.528243   \n",
       "2  0.204178          0.224480          -0.802786    -0.099287   \n",
       "3  0.046402          0.014496           1.297457    -1.188117   \n",
       "4  0.899461          0.985599          -0.890165     1.067473   \n",
       "\n",
       "   instability_index     gravy   reduced  oxidised     helix      turn  ...  \\\n",
       "0          -0.007247  0.305557 -0.509198 -0.508647  0.225385  0.012791  ...   \n",
       "1           1.152644  0.437546 -0.901343 -0.906719 -0.683724 -0.370318  ...   \n",
       "2           0.501211  0.927303 -0.435840 -0.429789  1.107682 -1.160093  ...   \n",
       "3           0.861330  0.038925 -0.447164 -0.428812 -1.140829  0.386568  ...   \n",
       "4          -0.433540  0.389393  0.506489  0.504784  1.612466 -0.363544  ...   \n",
       "\n",
       "   last_50_M  last_50_N  last_50_P  last_50_Q  last_50_R  last_50_S  \\\n",
       "0   0.854124  -0.162842   0.138739  -0.110699  -0.806124   1.403898   \n",
       "1  -0.016389  -0.162842  -0.289219   1.401648   0.907851  -0.787258   \n",
       "2  -0.886903  -1.227841   2.278529   0.897533  -0.806124  -0.056872   \n",
       "3   2.595151   0.369657   3.990361  -0.614815  -0.806124  -0.422065   \n",
       "4   0.854124  -0.695342  -1.145135  -0.110699   0.907851  -0.787258   \n",
       "\n",
       "   last_50_T  last_50_V  last_50_W  last_50_Y  \n",
       "0  -0.862108  -0.952807   0.422678   1.064776  \n",
       "1   0.793750  -0.426707   1.502267  -0.978975  \n",
       "2  -0.862108  -0.426707  -0.656912  -0.297724  \n",
       "3   1.345703   0.099393   0.422678  -0.978975  \n",
       "4  -0.862108   1.151592   0.422678   0.383526  \n",
       "\n",
       "[5 rows x 89 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length\n",
      "-8.531122921415614e-17\n",
      "molecular_weight\n",
      "-4.4375816598849574e-16\n",
      "isoelectric_point\n",
      "-1.2866571419565315e-16\n",
      "aromaticity\n",
      "-5.608863885643557e-15\n",
      "instability_index\n",
      "9.291542932318455e-16\n",
      "gravy\n",
      "-5.442459171229282e-15\n",
      "reduced\n",
      "-9.717976469551618e-17\n",
      "oxidised\n",
      "5.640006530398366e-18\n",
      "helix\n",
      "4.935054757633617e-15\n",
      "turn\n",
      "1.8224332405768527e-15\n",
      "sheet\n",
      "8.634975480522146e-15\n",
      "charge_at_ph1\n",
      "3.86460603993153e-15\n",
      "charge_at_ph7\n",
      "6.172128885657689e-17\n",
      "charge_at_ph12\n",
      "-5.974728657093747e-16\n",
      "hydrophobicity\n",
      "-2.651955592360835e-15\n",
      "flexibility\n",
      "1.5506673189505305e-13\n",
      "hydrophilicity\n",
      "9.183892372890417e-16\n",
      "surface_accessibility\n",
      "-3.666092523122022e-14\n",
      "janin\n",
      "2.369428047839162e-15\n",
      "first50_hydrophobicity\n",
      "1.882545288439702e-15\n",
      "first50_flexibility\n",
      "9.757628167637071e-14\n",
      "first50_hydrophilicity\n",
      "-4.2876310514789315e-16\n",
      "first50_surface_accessibility\n",
      "-3.3851126086531744e-14\n",
      "first50_janin\n",
      "7.09065299266811e-16\n",
      "last50_hydrophobicity\n",
      "-9.406550022003535e-17\n",
      "last50_flexibility\n",
      "2.1100801331999818e-13\n",
      "last50_hydrophilicity\n",
      "5.402022776583078e-16\n",
      "last50_surface_accessibility\n",
      "4.0643376755427676e-14\n",
      "last50_janin\n",
      "3.193586262977385e-15\n",
      "A\n",
      "-2.7060015679825654e-15\n",
      "C\n",
      "3.239448098688157e-16\n",
      "D\n",
      "-5.374153787792653e-15\n",
      "E\n",
      "-2.1664000736285825e-15\n",
      "F\n",
      "-1.0927414565576739e-14\n",
      "G\n",
      "-4.321213612102325e-15\n",
      "H\n",
      "-5.475207991756878e-15\n",
      "I\n",
      "-5.154549098736207e-15\n",
      "K\n",
      "-2.4366054299697113e-16\n",
      "L\n",
      "-1.0660347995478614e-15\n",
      "M\n",
      "-4.226200958611696e-15\n",
      "N\n",
      "-4.290524620046701e-15\n",
      "P\n",
      "-4.689297603513389e-16\n",
      "Q\n",
      "-4.81999862441349e-15\n",
      "R\n",
      "-6.011235438494315e-15\n",
      "S\n",
      "-1.832267542181094e-14\n",
      "T\n",
      "-7.01844558297431e-15\n",
      "V\n",
      "-6.731225951498067e-15\n",
      "W\n",
      "-2.7661779854851634e-16\n",
      "Y\n",
      "-6.7853339978438414e-15\n",
      "first_50_A\n",
      "1.122490038828773e-14\n",
      "first_50_C\n",
      "-3.108313732177602e-14\n",
      "first_50_D\n",
      "2.141096061721113e-14\n",
      "first_50_E\n",
      "2.4431404810147164e-14\n",
      "first_50_F\n",
      "1.2084989123289719e-14\n",
      "first_50_G\n",
      "2.5564972557454666e-14\n",
      "first_50_H\n",
      "-5.208950639987028e-14\n",
      "first_50_I\n",
      "1.7776123538974523e-14\n",
      "first_50_K\n",
      "1.8600324667205912e-14\n",
      "first_50_L\n",
      "-8.129922282964103e-15\n",
      "first_50_M\n",
      "3.9224676025799134e-14\n",
      "first_50_N\n",
      "1.906170172316002e-14\n",
      "first_50_P\n",
      "2.3280432738339878e-14\n",
      "first_50_Q\n",
      "1.8236530452500984e-14\n",
      "first_50_R\n",
      "2.476996459345997e-14\n",
      "first_50_S\n",
      "-4.037656153344666e-15\n",
      "first_50_T\n",
      "2.2140544505453204e-14\n",
      "first_50_V\n",
      "2.8840124349656995e-14\n",
      "first_50_W\n",
      "-2.021947245501319e-14\n",
      "first_50_Y\n",
      "-3.2691353765404473e-14\n",
      "last_50_A\n",
      "1.438714783237012e-14\n",
      "last_50_C\n",
      "-2.533174602653893e-14\n",
      "last_50_D\n",
      "1.1393401713825261e-14\n",
      "last_50_E\n",
      "1.3894867218894554e-14\n",
      "last_50_F\n",
      "1.2099530531431137e-14\n",
      "last_50_G\n",
      "1.3209679990753724e-14\n",
      "last_50_H\n",
      "-4.2549790919330534e-14\n",
      "last_50_I\n",
      "1.8843592861922506e-14\n",
      "last_50_K\n",
      "1.5510856296522713e-14\n",
      "last_50_L\n",
      "3.4971473535923153e-15\n",
      "last_50_M\n",
      "-5.33996553951143e-14\n",
      "last_50_N\n",
      "1.7565266990482076e-14\n",
      "last_50_P\n",
      "2.273166010293212e-14\n",
      "last_50_Q\n",
      "1.756085460493832e-14\n",
      "last_50_R\n",
      "2.024174435036638e-14\n",
      "last_50_S\n",
      "4.038391806370371e-15\n",
      "last_50_T\n",
      "1.8104718289009977e-14\n",
      "last_50_V\n",
      "1.6255258995401316e-14\n",
      "last_50_W\n",
      "-2.4190699140136772e-14\n",
      "last_50_Y\n",
      "-4.29214305670325e-15\n"
     ]
    }
   ],
   "source": [
    "for label in list(full_x.columns):\n",
    "    print(label)\n",
    "    print(full_x[label].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = collections.defaultdict(list)\n",
    "columns = ['params', \n",
    "           'mean_test_Accuracy', 'std_test_Accuracy', \n",
    "           'mean_test_Precision', 'std_test_Precision',\n",
    "           'mean_test_Recall', 'std_test_Recall',\n",
    "           'mean_test_F1', 'std_test_F1',\n",
    "           'mean_test_MCC', 'std_test_MCC']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test using Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] n_estimators=1000 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=1000, Accuracy=0.674, F1=0.688, MCC=0.541, Precision=0.702, Recall=0.679, total=  40.8s\n",
      "[CV] n_estimators=1000 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   40.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=1000, Accuracy=0.680, F1=0.691, MCC=0.551, Precision=0.701, Recall=0.686, total=  40.3s\n",
      "[CV] n_estimators=1000 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  1.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=1000, Accuracy=0.654, F1=0.674, MCC=0.516, Precision=0.676, Recall=0.672, total=  40.3s\n",
      "[CV] n_estimators=1000 ...............................................\n",
      "[CV]  n_estimators=1000, Accuracy=0.662, F1=0.687, MCC=0.525, Precision=0.699, Recall=0.678, total=  41.1s\n",
      "[CV] n_estimators=1000 ...............................................\n",
      "[CV]  n_estimators=1000, Accuracy=0.667, F1=0.687, MCC=0.533, Precision=0.694, Recall=0.682, total=  40.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  3.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best performance: 0.6672556598564329\n",
      "With the hyperparameters: {'n_estimators': 1000}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>params</th>\n",
       "      <td>{'n_estimators': 1000}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_Accuracy</th>\n",
       "      <td>0.6673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_test_Accuracy</th>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_Precision</th>\n",
       "      <td>0.6943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_test_Precision</th>\n",
       "      <td>0.0096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_Recall</th>\n",
       "      <td>0.6794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_test_Recall</th>\n",
       "      <td>0.0045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_F1</th>\n",
       "      <td>0.6854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_test_F1</th>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_MCC</th>\n",
       "      <td>0.5332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_test_MCC</th>\n",
       "      <td>0.0123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          0\n",
       "params               {'n_estimators': 1000}\n",
       "mean_test_Accuracy                   0.6673\n",
       "std_test_Accuracy                     0.009\n",
       "mean_test_Precision                  0.6943\n",
       "std_test_Precision                   0.0096\n",
       "mean_test_Recall                     0.6794\n",
       "std_test_Recall                      0.0045\n",
       "mean_test_F1                         0.6854\n",
       "std_test_F1                           0.006\n",
       "mean_test_MCC                        0.5332\n",
       "std_test_MCC                         0.0123"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Define some hyperparameters we are going to test\n",
    "param_dist = {\"n_estimators\": [1000]}\n",
    "\n",
    "# Make a handle for our model (initialization or our model without fitted parameters)\n",
    "rf = RandomForestClassifier(random_state=79)\n",
    "\n",
    "rf_random_search_res = cross_validate(rf,\n",
    "                                      full_x,\n",
    "                                      full_y,\n",
    "                                      param_dist,\n",
    "                                      5)\n",
    "\n",
    "print(\"Best performance: %s\" % (rf_random_search_res.best_score_))\n",
    "print(\"With the hyperparameters: %s\" % (rf_random_search_res.best_params_))\n",
    "\n",
    "# Print cross-validation results\n",
    "rf_df = pd.DataFrame.from_dict(rf_random_search_res.cv_results_)[columns].round(4)\n",
    "rf_result = rf_df[rf_df['params']==rf_random_search_res.best_params_].reset_index(drop=True).to_dict('records')[0]\n",
    "table = make_row(table, rf_result, \"RF\")\n",
    "rf_df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test using MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Define some hyperparameters we are going to test\n",
    "param_dist = {\"hidden_layer_sizes\": [100,128,256,512]}\n",
    "\n",
    "# Make a handle for our model (initialization or our model without fitted parameters)\n",
    "mlp = MLPClassifier(random_state=79)\n",
    "\n",
    "mlp_random_search_res = cross_validate(mlp,\n",
    "                                       full_x,\n",
    "                                       full_y,\n",
    "                                       param_dist,\n",
    "                                       5)\n",
    "\n",
    "print(\"Best pemlpormance: %s\" % (mlp_random_search_res.best_score_))\n",
    "print(\"With the hyperparameters: %s\" % (mlp_random_search_res.best_params_))\n",
    "\n",
    "# Print cross-validation results\n",
    "mlp_df = pd.DataFrame.from_dict(mlp_random_search_res.cv_results_)[columns].round(4)\n",
    "mlp_result = mlp_df[mlp_df['params']==mlp_random_search_res.best_params_].reset_index(drop=True).to_dict('records')[0]\n",
    "table = make_row(table, mlp_result, \"MLP\")\n",
    "mlp_df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test using SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Define some hyperparameters we are going to test\n",
    "param_dist = {\"C\": [1,2,3,5,10]}\n",
    "\n",
    "# Make a handle for our model (initialization or our model without fitted parameters)\n",
    "svm = SVC(random_state=79)\n",
    "\n",
    "svm_random_search_res = cross_validate(svm,\n",
    "                                       full_x,\n",
    "                                       full_y,\n",
    "                                       param_dist,\n",
    "                                       5)\n",
    "\n",
    "print(\"Best performance: %s\" % (svm_random_search_res.best_score_))\n",
    "print(\"With the hyperparameters: %s\" % (svm_random_search_res.best_params_))\n",
    "\n",
    "# Print cross-validation results\n",
    "svm_df = pd.DataFrame.from_dict(svm_random_search_res.cv_results_)[columns].round(4)\n",
    "svm_result = svm_df[svm_df['params']==svm_random_search_res.best_params_].reset_index(drop=True).to_dict('records')[0]\n",
    "table = make_row(table, svm_result, \"SVM\")\n",
    "svm_df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test using GNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "# Define some hyperparameters we are going to test\n",
    "param_dist = {\"priors\":[None]}\n",
    "\n",
    "# Make a handle for our model (initialization or our model without fitted parameters)\n",
    "gnb = GaussianNB()\n",
    "\n",
    "gnb_random_search_res = cross_validate(gnb,\n",
    "                                       full_x,\n",
    "                                       full_y,\n",
    "                                       param_dist,\n",
    "                                       5)\n",
    "\n",
    "print(\"Best pegnbormance: %s\" % (gnb_random_search_res.best_score_))\n",
    "print(\"With the hyperparameters: %s\" % (gnb_random_search_res.best_params_))\n",
    "\n",
    "# Print cross-validation results\n",
    "gnb_df = pd.DataFrame.from_dict(gnb_random_search_res.cv_results_)[columns].round(4)\n",
    "gnb_result = gnb_df[gnb_df['params']==gnb_random_search_res.best_params_].reset_index(drop=True).to_dict('records')[0]\n",
    "table = make_row(table, gnb_result, \"GNB\")\n",
    "gnb_df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test using LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "# Define some hyperparameters we are going to test\n",
    "param_dist = {\"priors\":[None]}\n",
    "\n",
    "# Make a handle for our model (initialization or our model without fitted parameters)\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "\n",
    "lda_random_search_res = cross_validate(lda,\n",
    "                                       full_x,\n",
    "                                       full_y,\n",
    "                                       param_dist,\n",
    "                                       5)\n",
    "\n",
    "print(\"Best peldaormance: %s\" % (lda_random_search_res.best_score_))\n",
    "print(\"With the hyperparameters: %s\" % (lda_random_search_res.best_params_))\n",
    "\n",
    "# Print cross-validation results\n",
    "lda_df = pd.DataFrame.from_dict(lda_random_search_res.cv_results_)[columns].round(4)\n",
    "lda_result = lda_df[lda_df['params']==lda_random_search_res.best_params_].reset_index(drop=True).to_dict('records')[0]\n",
    "table = make_row(table, lda_result, \"LDA\")\n",
    "lda_df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test using KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Define some hyperparameters we are going to test\n",
    "param_dist = {\"n_neighbors\":[1,2,3,4,5,6,7,8,9,10,15,20,25,30]}\n",
    "\n",
    "# Make a handle for our model (initialization or our model without fitted parameters)\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "knn_random_search_res = cross_validate(knn,\n",
    "                                       full_x,\n",
    "                                       full_y,\n",
    "                                       param_dist,\n",
    "                                       5)\n",
    "\n",
    "print(\"Best peknnormance: %s\" % (knn_random_search_res.best_score_))\n",
    "print(\"With the hyperparameters: %s\" % (knn_random_search_res.best_params_))\n",
    "\n",
    "# Print cross-validation results\n",
    "knn_df = pd.DataFrame.from_dict(knn_random_search_res.cv_results_)[columns].round(4)\n",
    "knn_result = knn_df[knn_df['params']==knn_random_search_res.best_params_].reset_index(drop=True).to_dict('records')[0]\n",
    "table = make_row(table, knn_result, \"KNN\")\n",
    "knn_df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.DataFrame.from_dict(table)\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(table.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Confusion Matrix and Classification Report and Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=1000, random_state=79)\n",
    "mean_conf_matrix, std_conf_matrix, class_reports = get_conf_matrix(rf, \n",
    "                                                                   full_x.to_numpy(), \n",
    "                                                                   full_y, classes, \n",
    "                                                                   n_splits=5)\n",
    "# Get labels for Confusion matrix plot\n",
    "mean_str = mean_conf_matrix.astype(str)\n",
    "std_str = std_conf_matrix.astype(str)\n",
    "labels = np.core.defchararray.add(mean_str,\"±\\n\")\n",
    "labels = np.core.defchararray.add(labels,std_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=1000, random_state=79)\n",
    "rf.fit(full_x, full_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = rf.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in rf.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure(figsize=(30,10))\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(train_x.shape[1]), \n",
    "        importances[indices], \n",
    "        color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(train_x.shape[1]), indices)\n",
    "plt.xlim([-1, train_x.shape[1]])\n",
    "plt.xlabel(\"Features\")\n",
    "plt.ylabel(\"Importance\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 24})\n",
    "# Plot averaged confusion matrix\n",
    "df_cm = pd.DataFrame(mean_conf_matrix, \n",
    "                     index = classes,\n",
    "                     columns = classes)\n",
    "plt.figure(figsize = (16,12))\n",
    "sns.heatmap(df_cm, annot=labels, fmt='', cmap='Blues',\n",
    "            cbar=True, square=True, center=15,\n",
    "            linewidths=.1, linecolor='black')\n",
    "plt.ylim((4,0))\n",
    "plt.title(\"Confusion Matrix \\n Mean Confusion Error (Counts) ± Std\")\n",
    "# plt.title(\"Normalised Confusion Matrix \\n Mean Proportion of True Labels Predicted to be in each class ± Std\")\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"confusion_matrix.pdf\", format=\"pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_reports = np.array(class_reports)\n",
    "pd.DataFrame(class_reports[:3,:]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.DataFrame(class_reports[:3,:], columns=classes).T.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test of blind test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = ['Cyto', 'Secr', 'Mito', 'Nucl']\n",
    "pred = rf.predict_proba(blind_test_x )\n",
    "seq_id = [seq.id for seq in blind_test_xs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blind_test_results = collections.defaultdict(list)\n",
    "for i, seq in enumerate(seq_id):\n",
    "    blind_test_results[seq].extend([class_labels[np.argmax(pred[i,:])], str(int((np.max(pred[i,:])*100).round(0)))])\n",
    "pd.DataFrame.from_dict(blind_test_results).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.DataFrame.from_dict(blind_test_results).T.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf = SVC(C=5,random_state=79,probability=True)\n",
    "rf = RandomForestClassifier(n_estimators=1000, random_state=79)\n",
    "rf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_proba_test = rf.predict_proba(test_x)\n",
    "pred_proba_test_label = np.argmax(pred_proba_test,axis=1)\n",
    "pred_proba_test_conf = np.max(pred_proba_test,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_proba_test_conf[test_y!=pred_proba_test_label].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_proba_test_conf[test_y==pred_proba_test_label].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
