{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/udeepa/Documents/UCL/Term 2/COMP0082 Bioinformatics/project\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "import pickle\n",
    "\n",
    "from Bio import SeqIO\n",
    "\n",
    "from proteios.preprocess import preprocess, split_data\n",
    "from proteios.featurise import Featuriser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"input_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cytosolic': 0, 'secreted': 1, 'mitochondrial': 2, 'nuclear': 3}\n",
      "{'cytosolic': 3004, 'secreted': 1605, 'mitochondrial': 1299, 'nuclear': 3314, 'total': 9222}\n",
      "Number of test data points:   20\n"
     ]
    }
   ],
   "source": [
    "classes = [\"cytosolic\", \"secreted\", \"mitochondrial\", \"nuclear\"]\n",
    "\n",
    "# Get dictionaries for labels\n",
    "label2index = {key:i for i, key in enumerate(classes)}\n",
    "index2label = dict(zip(label2index.values(), label2index.keys())) \n",
    "\n",
    "# Get data\n",
    "datasets = dict()\n",
    "for label in classes:\n",
    "    datasets[label] = list(SeqIO.parse(input_path+label+\".fasta\", \"fasta\"))\n",
    "# Get test data\n",
    "blind_test_x = list(SeqIO.parse(input_path+\"blind_test.fasta\", \"fasta\"))\n",
    "\n",
    "# Get number of examples in each category\n",
    "counts = {key:len(val) for i, (key,val) in enumerate(datasets.items())}\n",
    "counts[\"total\"] = sum([len(sublist) for keys, sublist in datasets.items()])\n",
    "print(label2index)\n",
    "print(counts)\n",
    "print(\"Number of test data points:  \", len(blind_test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing cytosolic\n",
      "Data removed:  80\n",
      "Processing secreted\n",
      "Data removed:  19\n",
      "Processing mitochondrial\n",
      "Data removed:  2\n",
      "Processing nuclear\n",
      "Data removed:  66\n",
      "Total Before:  9222\n",
      "Total After:   9055\n",
      "\n",
      "Processing tmp\n",
      "Data removed:  0\n",
      "Total Before:  20\n",
      "Total After:   20\n",
      "\n",
      "Training data size:  8148\n",
      "Test data size:      907\n",
      "Distribution train:  {1: 1427, 2: 1167, 3: 2923, 0: 2631}\n",
      "Distribution test:   {3: 325, 0: 293, 1: 159, 2: 130}\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the data\n",
    "full_x, full_y = preprocess(datasets, \n",
    "                            label2index=label2index,\n",
    "                            trim_outliers=True,\n",
    "                            max_length=2000)\n",
    "print()\n",
    "blind_test_x = preprocess(blind_test_x, \n",
    "                          trim_outliers=True,\n",
    "                          max_length=2000)\n",
    "# Split the data\n",
    "train_x, train_y, test_x, test_y = split_data(full_x, \n",
    "                                              full_y,\n",
    "                                              train_size=0.9)\n",
    "print()\n",
    "print(\"Training data size: \", len(train_y))\n",
    "print(\"Test data size:     \", len(test_y))\n",
    "print(\"Distribution train: \", dict(collections.Counter(train_y)))\n",
    "print(\"Distribution test:  \", dict(collections.Counter(test_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dictionaries\n",
    "dicts = dict()\n",
    "dicts['kd'] = pickle.load(open(\"input_data/scales/kd.pickle\",\"rb\"))\n",
    "dicts['flex'] = pickle.load(open(\"input_data/scales/flex.pickle\",\"rb\"))\n",
    "dicts['hw'] = pickle.load(open(\"input_data/scales/hw.pickle\",\"rb\"))\n",
    "dicts['em'] = pickle.load(open(\"input_data/scales/em.pickle\",\"rb\"))\n",
    "dicts['ja'] = pickle.load(open(\"input_data/scales/ja.pickle\",\"rb\"))\n",
    "dicts['diwv'] = pickle.load(open(\"input_data/scales/diwv.pickle\",\"rb\"))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuriser = Featuriser(train_x, dicts)\n",
    "full_x  = featuriser.transform(full_x)\n",
    "blind_test_x  = featuriser.transform(blind_test_x)\n",
    "train_x = featuriser.transform(train_x)\n",
    "test_x  = featuriser.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>molecular_weight</th>\n",
       "      <th>isoelectric_point</th>\n",
       "      <th>aromaticity</th>\n",
       "      <th>instability_index</th>\n",
       "      <th>gravy</th>\n",
       "      <th>reduced</th>\n",
       "      <th>oxidised</th>\n",
       "      <th>helix</th>\n",
       "      <th>turn</th>\n",
       "      <th>...</th>\n",
       "      <th>last_50_M</th>\n",
       "      <th>last_50_N</th>\n",
       "      <th>last_50_P</th>\n",
       "      <th>last_50_Q</th>\n",
       "      <th>last_50_R</th>\n",
       "      <th>last_50_S</th>\n",
       "      <th>last_50_T</th>\n",
       "      <th>last_50_V</th>\n",
       "      <th>last_50_W</th>\n",
       "      <th>last_50_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.807171</td>\n",
       "      <td>-0.800542</td>\n",
       "      <td>-0.761953</td>\n",
       "      <td>0.246225</td>\n",
       "      <td>-0.007813</td>\n",
       "      <td>0.311954</td>\n",
       "      <td>-0.510107</td>\n",
       "      <td>-0.509475</td>\n",
       "      <td>0.230534</td>\n",
       "      <td>0.013088</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.098216</td>\n",
       "      <td>-1.107380</td>\n",
       "      <td>1.167160</td>\n",
       "      <td>-1.513737</td>\n",
       "      <td>1.150809</td>\n",
       "      <td>0.443974</td>\n",
       "      <td>-0.902971</td>\n",
       "      <td>-0.908272</td>\n",
       "      <td>-0.674945</td>\n",
       "      <td>-0.371425</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.202142</td>\n",
       "      <td>0.221958</td>\n",
       "      <td>-0.809271</td>\n",
       "      <td>-0.093574</td>\n",
       "      <td>0.500089</td>\n",
       "      <td>0.933848</td>\n",
       "      <td>-0.436614</td>\n",
       "      <td>-0.430473</td>\n",
       "      <td>1.109309</td>\n",
       "      <td>-1.164094</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.044604</td>\n",
       "      <td>0.012434</td>\n",
       "      <td>1.293986</td>\n",
       "      <td>-1.175704</td>\n",
       "      <td>0.859814</td>\n",
       "      <td>0.045258</td>\n",
       "      <td>-0.447959</td>\n",
       "      <td>-0.429495</td>\n",
       "      <td>-1.130226</td>\n",
       "      <td>0.388235</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.896378</td>\n",
       "      <td>0.981413</td>\n",
       "      <td>-0.896776</td>\n",
       "      <td>1.066006</td>\n",
       "      <td>-0.433639</td>\n",
       "      <td>0.395809</td>\n",
       "      <td>0.507445</td>\n",
       "      <td>0.505802</td>\n",
       "      <td>1.612078</td>\n",
       "      <td>-0.364626</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     length  molecular_weight  isoelectric_point  aromaticity  \\\n",
       "0 -0.807171         -0.800542          -0.761953     0.246225   \n",
       "1 -1.098216         -1.107380           1.167160    -1.513737   \n",
       "2  0.202142          0.221958          -0.809271    -0.093574   \n",
       "3  0.044604          0.012434           1.293986    -1.175704   \n",
       "4  0.896378          0.981413          -0.896776     1.066006   \n",
       "\n",
       "   instability_index     gravy   reduced  oxidised     helix      turn  ...  \\\n",
       "0          -0.007813  0.311954 -0.510107 -0.509475  0.230534  0.013088  ...   \n",
       "1           1.150809  0.443974 -0.902971 -0.908272 -0.674945 -0.371425  ...   \n",
       "2           0.500089  0.933848 -0.436614 -0.430473  1.109309 -1.164094  ...   \n",
       "3           0.859814  0.045258 -0.447959 -0.429495 -1.130226  0.388235  ...   \n",
       "4          -0.433639  0.395809  0.507445  0.505802  1.612078 -0.364626  ...   \n",
       "\n",
       "   last_50_M  last_50_N  last_50_P  last_50_Q  last_50_R  last_50_S  \\\n",
       "0        0.2        0.2        0.3        0.2        0.1        0.8   \n",
       "1        0.1        0.2        0.2        0.5        0.5        0.2   \n",
       "2        0.0        0.0        0.8        0.4        0.1        0.4   \n",
       "3        0.4        0.3        1.2        0.1        0.1        0.3   \n",
       "4        0.2        0.1        0.0        0.2        0.5        0.2   \n",
       "\n",
       "   last_50_T  last_50_V  last_50_W  last_50_Y  \n",
       "0        0.1        0.1        0.1        0.3  \n",
       "1        0.4        0.2        0.2        0.0  \n",
       "2        0.1        0.2        0.0        0.1  \n",
       "3        0.5        0.3        0.1        0.0  \n",
       "4        0.1        0.5        0.1        0.2  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.head()[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report, matthews_corrcoef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models to try:\n",
    "1. SVM\n",
    "2. Random Forest\n",
    "3. Gaussian Naive Bayes\n",
    "4. HMM\n",
    "5. MLP\n",
    "6. LDA\n",
    "7. KDE\n",
    "8. KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(model, x, y, params, metric, n_splits=5):\n",
    "    \"\"\"\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : `sklearn` model\n",
    "        The model to cross validate.\n",
    "    x : `list`\n",
    "        The training data.\n",
    "    y : `list`\n",
    "        The corresponding labels.\n",
    "    params : `dict`\n",
    "        The hyperparameters to cross-validate.\n",
    "    metric : `sklearn.metrics.scorer._PredictScorer`\n",
    "        The metric to use to assess performance.\n",
    "    n_splits : `int`\n",
    "        The number of splits for k-fold cross-validation.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    \n",
    "    \"\"\"\n",
    "    # Define a CV strategy\n",
    "    cv = StratifiedKFold(n_splits=n_splits,\n",
    "                         shuffle=True,\n",
    "                         random_state=0)    \n",
    "\n",
    "    # Define how we are going to fit our model parameters using the CV, hyperparameters and what evaluation metric\n",
    "    grid_search = GridSearchCV(model,\n",
    "                               param_grid=params,\n",
    "                               verbose=5,\n",
    "                               scoring=metric,\n",
    "                               n_jobs=1,\n",
    "                               refit=True,\n",
    "                               cv=cv)\n",
    "\n",
    "    # Fit the model parameters using the earlier defined search\n",
    "    random_search_res = grid_search.fit(x, y)   \n",
    "    return random_search_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use accuracy scoring\n",
    "acc_metric = make_scorer(accuracy_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test using Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best performance: 0.654997239094423\n",
      "With the hyperparameters: {'n_estimators': 1000}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Define some hyperparameters we are going to test\n",
    "param_dist = {\"n_estimators\": [100,200,400,600,800,1000,1200,1400,1600,1800,2000]}\n",
    "\n",
    "# Make a handle for our model (initialization or our model without fitted parameters)\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "rf_random_search_res = cross_validate(rf,\n",
    "                                      full_x,\n",
    "                                      full_y,\n",
    "                                      param_dist,\n",
    "                                      acc_metric,\n",
    "                                      5)\n",
    "\n",
    "print(\"Best performance: %s\" % (rf_random_search_res.best_score_))\n",
    "print(\"With the hyperparameters: %s\" % (rf_random_search_res.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:   0.6350606394707828\n",
      "Precision:  0.655478880490308\n",
      "Recall:     0.6401673048440386\n",
      "F1 score:   0.6472271368956263\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    cytosolic       0.55      0.58      0.56       293\n",
      "     secreted       0.77      0.74      0.75       159\n",
      "mitochondrial       0.65      0.59      0.62       130\n",
      "      nuclear       0.64      0.65      0.65       325\n",
      "\n",
      "  avg / total       0.64      0.64      0.64       907\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=rf_random_search_res.best_params_['n_estimators'],\n",
    "                            random_state=0)\n",
    "rf.fit(train_x, train_y)\n",
    "rf_pred = rf.predict(test_x)\n",
    "acc = accuracy_score(test_y, rf_pred)\n",
    "precision = precision_score(test_y, rf_pred, average='macro')\n",
    "recall = recall_score(test_y, rf_pred, average='macro')\n",
    "f1 = f1_score(test_y, rf_pred, average='macro')\n",
    "print(\"Accuracy:  \", acc)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall:    \", recall)\n",
    "print(\"F1 score:  \", f1)\n",
    "print(classification_report(test_y, rf_pred, target_names = classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "importances = rf.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in rf.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure(figsize=(20,4))\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(train_x.shape[1]), \n",
    "        importances[indices], \n",
    "        color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(train_x.shape[1]), indices)\n",
    "plt.xlim([-1, train_x.shape[1]])\n",
    "plt.xlabel(\"Features\")\n",
    "plt.ylabel(\"Importance\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test using MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV] hidden_layer_sizes=100 ..........................................\n",
      "[CV] . hidden_layer_sizes=100, score=0.6845008273579702, total=   4.0s\n",
      "[CV] hidden_layer_sizes=100 ..........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . hidden_layer_sizes=100, score=0.6545253863134658, total=   5.7s\n",
      "[CV] hidden_layer_sizes=100 ..........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    9.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . hidden_layer_sizes=100, score=0.6543346217559359, total=   4.7s\n",
      "[CV] hidden_layer_sizes=100 ..........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   14.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . hidden_layer_sizes=100, score=0.6607734806629835, total=   6.2s\n",
      "[CV] hidden_layer_sizes=100 ..........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   20.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . hidden_layer_sizes=100, score=0.6395798783858485, total=   4.6s\n",
      "[CV] hidden_layer_sizes=128 ..........................................\n",
      "[CV] . hidden_layer_sizes=128, score=0.6762272476558191, total=   7.1s\n",
      "[CV] hidden_layer_sizes=128 ..........................................\n",
      "[CV] . hidden_layer_sizes=128, score=0.6589403973509934, total=   8.5s\n",
      "[CV] hidden_layer_sizes=128 ..........................................\n",
      "[CV] . hidden_layer_sizes=128, score=0.6427388183324131, total=   5.2s\n",
      "[CV] hidden_layer_sizes=128 ..........................................\n",
      "[CV] . hidden_layer_sizes=128, score=0.6635359116022099, total=   5.9s\n",
      "[CV] hidden_layer_sizes=128 ..........................................\n",
      "[CV] . hidden_layer_sizes=128, score=0.6462133775566611, total=   5.4s\n",
      "[CV] hidden_layer_sizes=256 ..........................................\n",
      "[CV] . hidden_layer_sizes=256, score=0.6712630998345284, total=  10.4s\n",
      "[CV] hidden_layer_sizes=256 ..........................................\n",
      "[CV] . hidden_layer_sizes=256, score=0.6572847682119205, total=   9.1s\n",
      "[CV] hidden_layer_sizes=256 ..........................................\n",
      "[CV] . hidden_layer_sizes=256, score=0.6659304251794589, total=   8.9s\n",
      "[CV] hidden_layer_sizes=256 ..........................................\n",
      "[CV] . hidden_layer_sizes=256, score=0.6480662983425415, total=  11.9s\n",
      "[CV] hidden_layer_sizes=256 ..........................................\n",
      "[CV] . hidden_layer_sizes=256, score=0.6478717523493643, total=   3.8s\n",
      "[CV] hidden_layer_sizes=512 ..........................................\n",
      "[CV] . hidden_layer_sizes=512, score=0.6607832322118037, total=  18.7s\n",
      "[CV] hidden_layer_sizes=512 ..........................................\n",
      "[CV] . hidden_layer_sizes=512, score=0.6622516556291391, total=  10.7s\n",
      "[CV] hidden_layer_sizes=512 ..........................................\n",
      "[CV] . hidden_layer_sizes=512, score=0.6543346217559359, total=  14.2s\n",
      "[CV] hidden_layer_sizes=512 ..........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . hidden_layer_sizes=512, score=0.6541436464088398, total=  20.9s\n",
      "[CV] hidden_layer_sizes=512 ..........................................\n",
      "[CV] . hidden_layer_sizes=512, score=0.6440022111663902, total=  16.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:  3.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best performance: 0.6587520706791827\n",
      "With the hyperparameters: {'hidden_layer_sizes': 100}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Define some hyperparameters we are going to test\n",
    "param_dist = {\"hidden_layer_sizes\": [100,128,256,512]}\n",
    "\n",
    "# Make a handle for our model (initialization or our model without fitted parameters)\n",
    "mlp = MLPClassifier()\n",
    "\n",
    "mlp_random_search_res = cross_validate(mlp,\n",
    "                                       full_x,\n",
    "                                       full_y,\n",
    "                                       param_dist,\n",
    "                                       acc_metric,\n",
    "                                       5)\n",
    "\n",
    "print(\"Best performance: %s\" % (mlp_random_search_res.best_score_))\n",
    "print(\"With the hyperparameters: %s\" % (mlp_random_search_res.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:   0.6405733186328556\n",
      "Precision:  0.6640277920608803\n",
      "Recall:     0.6720964167950452\n",
      "F1 score:   0.6651901787617006\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    cytosolic       0.54      0.62      0.58       293\n",
      "     secreted       0.74      0.75      0.75       159\n",
      "mitochondrial       0.69      0.76      0.73       130\n",
      "      nuclear       0.68      0.55      0.61       325\n",
      "\n",
      "  avg / total       0.65      0.64      0.64       907\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=mlp_random_search_res.best_params_[\"hidden_layer_sizes\"],\n",
    "                    activation='relu',\n",
    "                    solver='adam',\n",
    "                    alpha=0.0001,\n",
    "                    batch_size='auto',\n",
    "                    learning_rate='constant',\n",
    "                    learning_rate_init=0.001,\n",
    "                    random_state=0)\n",
    "mlp.fit(train_x, train_y)\n",
    "mlp_pred = mlp.predict(test_x)\n",
    "acc = accuracy_score(test_y, mlp_pred)\n",
    "precision = precision_score(test_y, mlp_pred, average='macro')\n",
    "recall = recall_score(test_y, mlp_pred, average='macro')\n",
    "f1 = f1_score(test_y, mlp_pred, average='macro')\n",
    "print(\"Accuracy:  \", acc)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall:    \", recall)\n",
    "print(\"F1 score:  \", f1)\n",
    "print(classification_report(test_y, mlp_pred, target_names = classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test using SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV] C=0.01, degree=1 ................................................\n",
      "[CV] ....... C=0.01, degree=1, score=0.4942084942084942, total=   8.1s\n",
      "[CV] C=0.01, degree=1 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   12.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....... C=0.01, degree=1, score=0.4806843267108168, total=   8.1s\n",
      "[CV] C=0.01, degree=1 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   25.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....... C=0.01, degree=1, score=0.4803975704030922, total=   8.3s\n",
      "[CV] C=0.01, degree=1 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   37.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........ C=0.01, degree=1, score=0.487292817679558, total=   8.2s\n",
      "[CV] C=0.01, degree=1 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   50.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...... C=0.01, degree=1, score=0.45550027639579876, total=   8.1s\n",
      "[CV] C=0.01, degree=2 ................................................\n",
      "[CV] ....... C=0.01, degree=2, score=0.4942084942084942, total=   8.1s\n",
      "[CV] C=0.01, degree=2 ................................................\n",
      "[CV] ....... C=0.01, degree=2, score=0.4806843267108168, total=   8.1s\n",
      "[CV] C=0.01, degree=2 ................................................\n",
      "[CV] ....... C=0.01, degree=2, score=0.4803975704030922, total=   8.1s\n",
      "[CV] C=0.01, degree=2 ................................................\n",
      "[CV] ........ C=0.01, degree=2, score=0.487292817679558, total=   8.1s\n",
      "[CV] C=0.01, degree=2 ................................................\n",
      "[CV] ...... C=0.01, degree=2, score=0.45550027639579876, total=   8.2s\n",
      "[CV] C=0.01, degree=3 ................................................\n",
      "[CV] ....... C=0.01, degree=3, score=0.4942084942084942, total=   8.2s\n",
      "[CV] C=0.01, degree=3 ................................................\n",
      "[CV] ....... C=0.01, degree=3, score=0.4806843267108168, total=   8.1s\n",
      "[CV] C=0.01, degree=3 ................................................\n",
      "[CV] ....... C=0.01, degree=3, score=0.4803975704030922, total=   8.1s\n",
      "[CV] C=0.01, degree=3 ................................................\n",
      "[CV] ........ C=0.01, degree=3, score=0.487292817679558, total=   8.1s\n",
      "[CV] C=0.01, degree=3 ................................................\n",
      "[CV] ...... C=0.01, degree=3, score=0.45550027639579876, total=   8.1s\n",
      "[CV] C=0.01, degree=4 ................................................\n",
      "[CV] ....... C=0.01, degree=4, score=0.4942084942084942, total=   8.1s\n",
      "[CV] C=0.01, degree=4 ................................................\n",
      "[CV] ....... C=0.01, degree=4, score=0.4806843267108168, total=   8.1s\n",
      "[CV] C=0.01, degree=4 ................................................\n",
      "[CV] ....... C=0.01, degree=4, score=0.4803975704030922, total=   8.1s\n",
      "[CV] C=0.01, degree=4 ................................................\n",
      "[CV] ........ C=0.01, degree=4, score=0.487292817679558, total=   8.1s\n",
      "[CV] C=0.01, degree=4 ................................................\n",
      "[CV] ...... C=0.01, degree=4, score=0.45550027639579876, total=   8.1s\n",
      "[CV] C=0.01, degree=5 ................................................\n",
      "[CV] ....... C=0.01, degree=5, score=0.4942084942084942, total=   8.2s\n",
      "[CV] C=0.01, degree=5 ................................................\n",
      "[CV] ....... C=0.01, degree=5, score=0.4806843267108168, total=  10.4s\n",
      "[CV] C=0.01, degree=5 ................................................\n",
      "[CV] ....... C=0.01, degree=5, score=0.4803975704030922, total=   8.3s\n",
      "[CV] C=0.01, degree=5 ................................................\n",
      "[CV] ........ C=0.01, degree=5, score=0.487292817679558, total=   8.7s\n",
      "[CV] C=0.01, degree=5 ................................................\n",
      "[CV] ...... C=0.01, degree=5, score=0.45550027639579876, total=   8.1s\n",
      "[CV] C=0.1, degree=1 .................................................\n",
      "[CV] ........ C=0.1, degree=1, score=0.5763927192498621, total=   6.8s\n",
      "[CV] C=0.1, degree=1 .................................................\n",
      "[CV] ........ C=0.1, degree=1, score=0.5838852097130243, total=   6.9s\n",
      "[CV] C=0.1, degree=1 .................................................\n",
      "[CV] ........ C=0.1, degree=1, score=0.5698509110988405, total=   7.4s\n",
      "[CV] C=0.1, degree=1 .................................................\n",
      "[CV] ........ C=0.1, degree=1, score=0.5668508287292817, total=   8.2s\n",
      "[CV] C=0.1, degree=1 .................................................\n",
      "[CV] ......... C=0.1, degree=1, score=0.552791597567717, total=   6.8s\n",
      "[CV] C=0.1, degree=2 .................................................\n",
      "[CV] ........ C=0.1, degree=2, score=0.5763927192498621, total=   7.1s\n",
      "[CV] C=0.1, degree=2 .................................................\n",
      "[CV] ........ C=0.1, degree=2, score=0.5838852097130243, total=   6.9s\n",
      "[CV] C=0.1, degree=2 .................................................\n",
      "[CV] ........ C=0.1, degree=2, score=0.5698509110988405, total=   7.1s\n",
      "[CV] C=0.1, degree=2 .................................................\n",
      "[CV] ........ C=0.1, degree=2, score=0.5668508287292817, total=   6.7s\n",
      "[CV] C=0.1, degree=2 .................................................\n",
      "[CV] ......... C=0.1, degree=2, score=0.552791597567717, total=   6.9s\n",
      "[CV] C=0.1, degree=3 .................................................\n",
      "[CV] ........ C=0.1, degree=3, score=0.5763927192498621, total=   6.8s\n",
      "[CV] C=0.1, degree=3 .................................................\n",
      "[CV] ........ C=0.1, degree=3, score=0.5838852097130243, total=   6.8s\n",
      "[CV] C=0.1, degree=3 .................................................\n",
      "[CV] ........ C=0.1, degree=3, score=0.5698509110988405, total=   6.8s\n",
      "[CV] C=0.1, degree=3 .................................................\n",
      "[CV] ........ C=0.1, degree=3, score=0.5668508287292817, total=   6.8s\n",
      "[CV] C=0.1, degree=3 .................................................\n",
      "[CV] ......... C=0.1, degree=3, score=0.552791597567717, total=   6.7s\n",
      "[CV] C=0.1, degree=4 .................................................\n",
      "[CV] ........ C=0.1, degree=4, score=0.5763927192498621, total=   6.9s\n",
      "[CV] C=0.1, degree=4 .................................................\n",
      "[CV] ........ C=0.1, degree=4, score=0.5838852097130243, total=   6.8s\n",
      "[CV] C=0.1, degree=4 .................................................\n",
      "[CV] ........ C=0.1, degree=4, score=0.5698509110988405, total=   6.8s\n",
      "[CV] C=0.1, degree=4 .................................................\n",
      "[CV] ........ C=0.1, degree=4, score=0.5668508287292817, total=   7.4s\n",
      "[CV] C=0.1, degree=4 .................................................\n",
      "[CV] ......... C=0.1, degree=4, score=0.552791597567717, total=   6.8s\n",
      "[CV] C=0.1, degree=5 .................................................\n",
      "[CV] ........ C=0.1, degree=5, score=0.5763927192498621, total=   7.2s\n",
      "[CV] C=0.1, degree=5 .................................................\n",
      "[CV] ........ C=0.1, degree=5, score=0.5838852097130243, total=   7.2s\n",
      "[CV] C=0.1, degree=5 .................................................\n",
      "[CV] ........ C=0.1, degree=5, score=0.5698509110988405, total=   7.2s\n",
      "[CV] C=0.1, degree=5 .................................................\n",
      "[CV] ........ C=0.1, degree=5, score=0.5668508287292817, total=   7.5s\n",
      "[CV] C=0.1, degree=5 .................................................\n",
      "[CV] ......... C=0.1, degree=5, score=0.552791597567717, total=   7.4s\n",
      "[CV] C=1.0, degree=1 .................................................\n",
      "[CV] ........ C=1.0, degree=1, score=0.6442360728075014, total=   6.2s\n",
      "[CV] C=1.0, degree=1 .................................................\n",
      "[CV] ........ C=1.0, degree=1, score=0.6379690949227373, total=   5.8s\n",
      "[CV] C=1.0, degree=1 .................................................\n",
      "[CV] ........ C=1.0, degree=1, score=0.6283821093318609, total=   6.0s\n",
      "[CV] C=1.0, degree=1 .................................................\n",
      "[CV] ........ C=1.0, degree=1, score=0.6337016574585635, total=   6.0s\n",
      "[CV] C=1.0, degree=1 .................................................\n",
      "[CV] ........ C=1.0, degree=1, score=0.6108347153123272, total=   6.3s\n",
      "[CV] C=1.0, degree=2 .................................................\n",
      "[CV] ........ C=1.0, degree=2, score=0.6442360728075014, total=   7.3s\n",
      "[CV] C=1.0, degree=2 .................................................\n",
      "[CV] ........ C=1.0, degree=2, score=0.6379690949227373, total=   6.2s\n",
      "[CV] C=1.0, degree=2 .................................................\n",
      "[CV] ........ C=1.0, degree=2, score=0.6283821093318609, total=   6.0s\n",
      "[CV] C=1.0, degree=2 .................................................\n",
      "[CV] ........ C=1.0, degree=2, score=0.6337016574585635, total=   6.2s\n",
      "[CV] C=1.0, degree=2 .................................................\n",
      "[CV] ........ C=1.0, degree=2, score=0.6108347153123272, total=   5.9s\n",
      "[CV] C=1.0, degree=3 .................................................\n",
      "[CV] ........ C=1.0, degree=3, score=0.6442360728075014, total=   6.1s\n",
      "[CV] C=1.0, degree=3 .................................................\n",
      "[CV] ........ C=1.0, degree=3, score=0.6379690949227373, total=   6.8s\n",
      "[CV] C=1.0, degree=3 .................................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........ C=1.0, degree=3, score=0.6283821093318609, total=   6.2s\n",
      "[CV] C=1.0, degree=3 .................................................\n",
      "[CV] ........ C=1.0, degree=3, score=0.6337016574585635, total=   6.0s\n",
      "[CV] C=1.0, degree=3 .................................................\n",
      "[CV] ........ C=1.0, degree=3, score=0.6108347153123272, total=   6.0s\n",
      "[CV] C=1.0, degree=4 .................................................\n",
      "[CV] ........ C=1.0, degree=4, score=0.6442360728075014, total=   6.0s\n",
      "[CV] C=1.0, degree=4 .................................................\n",
      "[CV] ........ C=1.0, degree=4, score=0.6379690949227373, total=   6.3s\n",
      "[CV] C=1.0, degree=4 .................................................\n",
      "[CV] ........ C=1.0, degree=4, score=0.6283821093318609, total=   6.0s\n",
      "[CV] C=1.0, degree=4 .................................................\n",
      "[CV] ........ C=1.0, degree=4, score=0.6337016574585635, total=   6.1s\n",
      "[CV] C=1.0, degree=4 .................................................\n",
      "[CV] ........ C=1.0, degree=4, score=0.6108347153123272, total=   5.7s\n",
      "[CV] C=1.0, degree=5 .................................................\n",
      "[CV] ........ C=1.0, degree=5, score=0.6442360728075014, total=   6.0s\n",
      "[CV] C=1.0, degree=5 .................................................\n",
      "[CV] ........ C=1.0, degree=5, score=0.6379690949227373, total=   5.8s\n",
      "[CV] C=1.0, degree=5 .................................................\n",
      "[CV] ........ C=1.0, degree=5, score=0.6283821093318609, total=   5.9s\n",
      "[CV] C=1.0, degree=5 .................................................\n",
      "[CV] ........ C=1.0, degree=5, score=0.6337016574585635, total=   6.1s\n",
      "[CV] C=1.0, degree=5 .................................................\n",
      "[CV] ........ C=1.0, degree=5, score=0.6108347153123272, total=   6.2s\n",
      "[CV] C=10, degree=1 ..................................................\n",
      "[CV] ......... C=10, degree=1, score=0.6867071152785439, total=   5.5s\n",
      "[CV] C=10, degree=1 ..................................................\n",
      "[CV] ......... C=10, degree=1, score=0.6710816777041942, total=   5.6s\n",
      "[CV] C=10, degree=1 ..................................................\n",
      "[CV] ......... C=10, degree=1, score=0.6604086140254003, total=   5.6s\n",
      "[CV] C=10, degree=1 ..................................................\n",
      "[CV] ......... C=10, degree=1, score=0.6723756906077348, total=   5.5s\n",
      "[CV] C=10, degree=1 ..................................................\n",
      "[CV] ......... C=10, degree=1, score=0.6462133775566611, total=   5.7s\n",
      "[CV] C=10, degree=2 ..................................................\n",
      "[CV] ......... C=10, degree=2, score=0.6867071152785439, total=   5.7s\n",
      "[CV] C=10, degree=2 ..................................................\n",
      "[CV] ......... C=10, degree=2, score=0.6710816777041942, total=   5.9s\n",
      "[CV] C=10, degree=2 ..................................................\n",
      "[CV] ......... C=10, degree=2, score=0.6604086140254003, total=   5.6s\n",
      "[CV] C=10, degree=2 ..................................................\n",
      "[CV] ......... C=10, degree=2, score=0.6723756906077348, total=   5.8s\n",
      "[CV] C=10, degree=2 ..................................................\n",
      "[CV] ......... C=10, degree=2, score=0.6462133775566611, total=   5.5s\n",
      "[CV] C=10, degree=3 ..................................................\n",
      "[CV] ......... C=10, degree=3, score=0.6867071152785439, total=   5.8s\n",
      "[CV] C=10, degree=3 ..................................................\n",
      "[CV] ......... C=10, degree=3, score=0.6710816777041942, total=   5.5s\n",
      "[CV] C=10, degree=3 ..................................................\n",
      "[CV] ......... C=10, degree=3, score=0.6604086140254003, total=   5.8s\n",
      "[CV] C=10, degree=3 ..................................................\n",
      "[CV] ......... C=10, degree=3, score=0.6723756906077348, total=   5.6s\n",
      "[CV] C=10, degree=3 ..................................................\n",
      "[CV] ......... C=10, degree=3, score=0.6462133775566611, total=   5.6s\n",
      "[CV] C=10, degree=4 ..................................................\n",
      "[CV] ......... C=10, degree=4, score=0.6867071152785439, total=   5.8s\n",
      "[CV] C=10, degree=4 ..................................................\n",
      "[CV] ......... C=10, degree=4, score=0.6710816777041942, total=   5.4s\n",
      "[CV] C=10, degree=4 ..................................................\n",
      "[CV] ......... C=10, degree=4, score=0.6604086140254003, total=   5.3s\n",
      "[CV] C=10, degree=4 ..................................................\n",
      "[CV] ......... C=10, degree=4, score=0.6723756906077348, total=   5.8s\n",
      "[CV] C=10, degree=4 ..................................................\n",
      "[CV] ......... C=10, degree=4, score=0.6462133775566611, total=   5.5s\n",
      "[CV] C=10, degree=5 ..................................................\n",
      "[CV] ......... C=10, degree=5, score=0.6867071152785439, total=   5.5s\n",
      "[CV] C=10, degree=5 ..................................................\n",
      "[CV] ......... C=10, degree=5, score=0.6710816777041942, total=   5.4s\n",
      "[CV] C=10, degree=5 ..................................................\n",
      "[CV] ......... C=10, degree=5, score=0.6604086140254003, total=   5.0s\n",
      "[CV] C=10, degree=5 ..................................................\n",
      "[CV] ......... C=10, degree=5, score=0.6723756906077348, total=   5.0s\n",
      "[CV] C=10, degree=5 ..................................................\n",
      "[CV] ......... C=10, degree=5, score=0.6462133775566611, total=   5.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed: 18.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best performance: 0.667366096079514\n",
      "With the hyperparameters: {'C': 10, 'degree': 1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Define some hyperparameters we are going to test\n",
    "param_dist = {\"C\": [0.01,0.1,1.0,10], \"degree\":[1,2,3,4,5]}\n",
    "\n",
    "# Make a handle for our model (initialization or our model without fitted parameters)\n",
    "svm = SVC()\n",
    "\n",
    "svm_random_search_res = cross_validate(svm,\n",
    "                                       full_x,\n",
    "                                       full_y,\n",
    "                                       param_dist,\n",
    "                                       acc_metric,\n",
    "                                       5)\n",
    "\n",
    "print(\"Best performance: %s\" % (svm_random_search_res.best_score_))\n",
    "print(\"With the hyperparameters: %s\" % (svm_random_search_res.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:   0.6295479603087101\n",
      "Precision:  0.6502584100309114\n",
      "Recall:     0.6548296817699226\n",
      "F1 score:   0.6522843543732636\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    cytosolic       0.53      0.55      0.54       293\n",
      "     secreted       0.75      0.74      0.74       159\n",
      "mitochondrial       0.68      0.72      0.70       130\n",
      "      nuclear       0.64      0.61      0.63       325\n",
      "\n",
      "  avg / total       0.63      0.63      0.63       907\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(C=svm_random_search_res.best_params_['C'],\n",
    "          kernel='rbf',\n",
    "          degree=svm_random_search_res.best_params_['degree'],\n",
    "          decision_function_shape='ovr',\n",
    "          probability=False)\n",
    "svm.fit(train_x, train_y)\n",
    "svm_pred = svm.predict(test_x)\n",
    "acc = accuracy_score(test_y, svm_pred)\n",
    "precision = precision_score(test_y, svm_pred, average='macro')\n",
    "recall = recall_score(test_y, svm_pred, average='macro')\n",
    "f1 = f1_score(test_y, svm_pred, average='macro')\n",
    "print(\"Accuracy:  \", acc)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall:    \", recall)\n",
    "print(\"F1 score:  \", f1)\n",
    "print(classification_report(test_y, svm_pred, target_names = classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test using KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] .......... n_neighbors=1, score=0.5543298400441258, total=   1.0s\n",
      "[CV] n_neighbors=1 ...................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......... n_neighbors=1, score=0.5584988962472406, total=   1.0s\n",
      "[CV] n_neighbors=1 ...................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    2.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......... n_neighbors=1, score=0.5670900055218111, total=   1.1s\n",
      "[CV] n_neighbors=1 ...................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    4.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........... n_neighbors=1, score=0.543646408839779, total=   1.0s\n",
      "[CV] n_neighbors=1 ...................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    5.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........... n_neighbors=1, score=0.574350469872858, total=   1.1s\n",
      "[CV] n_neighbors=2 ...................................................\n",
      "[CV] .......... n_neighbors=2, score=0.5267512410369554, total=   1.3s\n",
      "[CV] n_neighbors=2 ...................................................\n",
      "[CV] .......... n_neighbors=2, score=0.5298013245033113, total=   1.0s\n",
      "[CV] n_neighbors=2 ...................................................\n",
      "[CV] .......... n_neighbors=2, score=0.5256764218663722, total=   1.1s\n",
      "[CV] n_neighbors=2 ...................................................\n",
      "[CV] .......... n_neighbors=2, score=0.5226519337016574, total=   1.0s\n",
      "[CV] n_neighbors=2 ...................................................\n",
      "[CV] .......... n_neighbors=2, score=0.5334438916528469, total=   1.2s\n",
      "[CV] n_neighbors=3 ...................................................\n",
      "[CV] .......... n_neighbors=3, score=0.5703254274682846, total=   1.1s\n",
      "[CV] n_neighbors=3 ...................................................\n",
      "[CV] .......... n_neighbors=3, score=0.5745033112582781, total=   1.2s\n",
      "[CV] n_neighbors=3 ...................................................\n",
      "[CV] .......... n_neighbors=3, score=0.5742683600220873, total=   1.2s\n",
      "[CV] n_neighbors=3 ...................................................\n",
      "[CV] .......... n_neighbors=3, score=0.5718232044198895, total=   1.1s\n",
      "[CV] n_neighbors=3 ...................................................\n",
      "[CV] .......... n_neighbors=3, score=0.5666113875069099, total=   1.0s\n",
      "[CV] n_neighbors=4 ...................................................\n",
      "[CV] .......... n_neighbors=4, score=0.5741864313292885, total=   1.1s\n",
      "[CV] n_neighbors=4 ...................................................\n",
      "[CV] .......... n_neighbors=4, score=0.5634657836644592, total=   1.2s\n",
      "[CV] n_neighbors=4 ...................................................\n",
      "[CV] .......... n_neighbors=4, score=0.5748205411374931, total=   1.2s\n",
      "[CV] n_neighbors=4 ...................................................\n",
      "[CV] ........... n_neighbors=4, score=0.569060773480663, total=   1.0s\n",
      "[CV] n_neighbors=4 ...................................................\n",
      "[CV] .......... n_neighbors=4, score=0.5671641791044776, total=   1.2s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] .......... n_neighbors=5, score=0.5824600110314396, total=   1.2s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] .......... n_neighbors=5, score=0.5739514348785872, total=   1.2s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] .......... n_neighbors=5, score=0.5875207067918278, total=   1.1s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] .......... n_neighbors=5, score=0.5696132596685083, total=   1.1s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] .......... n_neighbors=5, score=0.5699281370923162, total=   1.1s\n",
      "[CV] n_neighbors=6 ...................................................\n",
      "[CV] .......... n_neighbors=6, score=0.5945945945945946, total=   1.1s\n",
      "[CV] n_neighbors=6 ...................................................\n",
      "[CV] .......... n_neighbors=6, score=0.5711920529801324, total=   1.3s\n",
      "[CV] n_neighbors=6 ...................................................\n",
      "[CV] .......... n_neighbors=6, score=0.5941468801766979, total=   1.1s\n",
      "[CV] n_neighbors=6 ...................................................\n",
      "[CV] .......... n_neighbors=6, score=0.5845303867403315, total=   1.1s\n",
      "[CV] n_neighbors=6 ...................................................\n",
      "[CV] .......... n_neighbors=6, score=0.5771144278606966, total=   1.1s\n",
      "[CV] n_neighbors=7 ...................................................\n",
      "[CV] .......... n_neighbors=7, score=0.6028681742967458, total=   1.5s\n",
      "[CV] n_neighbors=7 ...................................................\n",
      "[CV] .......... n_neighbors=7, score=0.5783664459161147, total=   1.3s\n",
      "[CV] n_neighbors=7 ...................................................\n",
      "[CV] .......... n_neighbors=7, score=0.6046383213694092, total=   1.4s\n",
      "[CV] n_neighbors=7 ...................................................\n",
      "[CV] .......... n_neighbors=7, score=0.5950276243093923, total=   1.2s\n",
      "[CV] n_neighbors=7 ...................................................\n",
      "[CV] ............ n_neighbors=7, score=0.58595909342178, total=   1.3s\n",
      "[CV] n_neighbors=8 ...................................................\n",
      "[CV] .......... n_neighbors=8, score=0.6056260341974627, total=   1.1s\n",
      "[CV] n_neighbors=8 ...................................................\n",
      "[CV] .......... n_neighbors=8, score=0.5833333333333334, total=   1.1s\n",
      "[CV] n_neighbors=8 ...................................................\n",
      "[CV] .......... n_neighbors=8, score=0.5969077857537273, total=   1.1s\n",
      "[CV] n_neighbors=8 ...................................................\n",
      "[CV] .......... n_neighbors=8, score=0.5895027624309392, total=   1.0s\n",
      "[CV] n_neighbors=8 ...................................................\n",
      "[CV] .......... n_neighbors=8, score=0.5925925925925926, total=   1.2s\n",
      "[CV] n_neighbors=9 ...................................................\n",
      "[CV] .......... n_neighbors=9, score=0.6067291781577496, total=   1.2s\n",
      "[CV] n_neighbors=9 ...................................................\n",
      "[CV] .......... n_neighbors=9, score=0.5932671081677704, total=   1.2s\n",
      "[CV] n_neighbors=9 ...................................................\n",
      "[CV] .......... n_neighbors=9, score=0.5985643290999448, total=   1.2s\n",
      "[CV] n_neighbors=9 ...................................................\n",
      "[CV] .......... n_neighbors=9, score=0.5883977900552486, total=   1.2s\n",
      "[CV] n_neighbors=9 ...................................................\n",
      "[CV] .......... n_neighbors=9, score=0.5837479270315091, total=   1.1s\n",
      "[CV] n_neighbors=10 ..................................................\n",
      "[CV] .......... n_neighbors=10, score=0.604522890237176, total=   1.1s\n",
      "[CV] n_neighbors=10 ..................................................\n",
      "[CV] ......... n_neighbors=10, score=0.5960264900662252, total=   1.4s\n",
      "[CV] n_neighbors=10 ..................................................\n",
      "[CV] ......... n_neighbors=10, score=0.5969077857537273, total=   1.1s\n",
      "[CV] n_neighbors=10 ..................................................\n",
      "[CV] ......... n_neighbors=10, score=0.5828729281767956, total=   1.1s\n",
      "[CV] n_neighbors=10 ..................................................\n",
      "[CV] ......... n_neighbors=10, score=0.5843007186290768, total=   1.2s\n",
      "[CV] n_neighbors=15 ..................................................\n",
      "[CV] .......... n_neighbors=15, score=0.604522890237176, total=   1.6s\n",
      "[CV] n_neighbors=15 ..................................................\n",
      "[CV] ......... n_neighbors=15, score=0.5938189845474614, total=   1.3s\n",
      "[CV] n_neighbors=15 ..................................................\n",
      "[CV] ......... n_neighbors=15, score=0.5935946990612921, total=   1.3s\n",
      "[CV] n_neighbors=15 ..................................................\n",
      "[CV] ......... n_neighbors=15, score=0.5950276243093923, total=   1.5s\n",
      "[CV] n_neighbors=15 ..................................................\n",
      "[CV] ......... n_neighbors=15, score=0.5771144278606966, total=   1.3s\n",
      "[CV] n_neighbors=20 ..................................................\n",
      "[CV] .......... n_neighbors=20, score=0.607280750137893, total=   1.5s\n",
      "[CV] n_neighbors=20 ..................................................\n",
      "[CV] ......... n_neighbors=20, score=0.5949227373068433, total=   1.6s\n",
      "[CV] n_neighbors=20 ..................................................\n",
      "[CV] ......... n_neighbors=20, score=0.5941468801766979, total=   1.4s\n",
      "[CV] n_neighbors=20 ..................................................\n",
      "[CV] ......... n_neighbors=20, score=0.5900552486187846, total=   1.3s\n",
      "[CV] n_neighbors=20 ..................................................\n",
      "[CV] .......... n_neighbors=20, score=0.582089552238806, total=   1.4s\n",
      "[CV] n_neighbors=25 ..................................................\n",
      "[CV] ......... n_neighbors=25, score=0.6034197462768891, total=   1.5s\n",
      "[CV] n_neighbors=25 ..................................................\n",
      "[CV] ......... n_neighbors=25, score=0.6048565121412803, total=   1.5s\n",
      "[CV] n_neighbors=25 ..................................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......... n_neighbors=25, score=0.5946990612921038, total=   1.5s\n",
      "[CV] n_neighbors=25 ..................................................\n",
      "[CV] ......... n_neighbors=25, score=0.5917127071823205, total=   1.4s\n",
      "[CV] n_neighbors=25 ..................................................\n",
      "[CV] ......... n_neighbors=25, score=0.5865118850193477, total=   1.3s\n",
      "[CV] n_neighbors=30 ..................................................\n",
      "[CV] ......... n_neighbors=30, score=0.6067291781577496, total=   1.4s\n",
      "[CV] n_neighbors=30 ..................................................\n",
      "[CV] ......... n_neighbors=30, score=0.5954746136865342, total=   1.4s\n",
      "[CV] n_neighbors=30 ..................................................\n",
      "[CV] .......... n_neighbors=30, score=0.597459966869133, total=   1.3s\n",
      "[CV] n_neighbors=30 ..................................................\n",
      "[CV] ......... n_neighbors=30, score=0.5867403314917127, total=   1.4s\n",
      "[CV] n_neighbors=30 ..................................................\n",
      "[CV] ......... n_neighbors=30, score=0.5771144278606966, total=   1.4s\n",
      "Best performance: 0.5962451684152402\n",
      "With the hyperparameters: {'n_neighbors': 25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  70 out of  70 | elapsed:  6.6min finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Define some hyperparameters we are going to test\n",
    "param_dist = {\"n_neighbors\":[1,2,3,4,5,6,7,8,9,10,15,20,25,30]}\n",
    "\n",
    "# Make a handle for our model (initialization or our model without fitted parameters)\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "knn_random_search_res = cross_validate(knn,\n",
    "                                       full_x,\n",
    "                                       full_y,\n",
    "                                       param_dist,\n",
    "                                       acc_metric,\n",
    "                                       5)\n",
    "\n",
    "print(\"Best performance: %s\" % (knn_random_search_res.best_score_))\n",
    "print(\"With the hyperparameters: %s\" % (knn_random_search_res.best_params_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:   0.587651598676957\n",
      "Precision:  0.6235855613212289\n",
      "Recall:     0.5931552711139292\n",
      "F1 score:   0.5999472526916692\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    cytosolic       0.50      0.63      0.56       293\n",
      "     secreted       0.81      0.57      0.67       159\n",
      "mitochondrial       0.55      0.63      0.59       130\n",
      "      nuclear       0.64      0.54      0.59       325\n",
      "\n",
      "  avg / total       0.61      0.59      0.59       907\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=knn_random_search_res.best_params_['n_neighbors'])\n",
    "knn.fit(train_x.to_numpy(), train_y)\n",
    "knn_pred = knn.predict(test_x.to_numpy())\n",
    "acc = accuracy_score(test_y, knn_pred)\n",
    "precision = precision_score(test_y, knn_pred, average='macro')\n",
    "recall = recall_score(test_y, knn_pred, average='macro')\n",
    "f1 = f1_score(test_y, knn_pred, average='macro')\n",
    "print(\"Accuracy:  \", acc)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall:    \", recall)\n",
    "print(\"F1 score:  \", f1)\n",
    "print(classification_report(test_y, knn_pred, target_names = classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test using GNB"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# Create a Count Vectorizer to gather the unique elements in sequence\n",
    "vect = CountVectorizer(analyzer = 'char_wb', \n",
    "                       ngram_range = (4,4),\n",
    "                       max_features=None)\n",
    "vect.fit([str(example.seq) for example in train_data])\n",
    "a = vect.transform([str(example.seq) for example in train_data])\n",
    "b = vect.transform([str(example.seq) for example in test_data])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model = MultinomialNB()\n",
    "model.fit(a, train_labels)\n",
    "NB_pred = model.predict(b)\n",
    "NB_pred"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "acc = accuracy_score(test_labels, NB_pred)\n",
    "precision = precision_score(test_labels, NB_pred, average='macro')\n",
    "recall = recall_score(test_labels, NB_pred, average='macro')\n",
    "f1 = f1_score(test_labels, NB_pred, average='macro')\n",
    "print(\"Accuracy:       \", acc)\n",
    "print(\"Precision:      \", precision)\n",
    "print(\"Recall:         \", recall)\n",
    "print(\"F1 score:       \", f1)\n",
    "print(classification_report(NB_pred, pred, target_names = classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.device"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
